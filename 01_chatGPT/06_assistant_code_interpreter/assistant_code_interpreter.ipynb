{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-ways of LLM connectivity\n",
    "* Chat: string input & string output\n",
    "* ChatCompletion: list of conversation as input & string output\n",
    "    * Chat & ChatCompletion are stateless\n",
    "        * means we need to provide information to LLM evey time we communicate with it\n",
    "\n",
    "        * There are four ways by wich we can provide pevious conversation's history to LLM\n",
    "            * Providing complete history of previous conversations\n",
    "            * Fixing wondow (no of latest conversations)\n",
    "            * Fixing tokens limit\n",
    "            * Summerization\n",
    "* Assistant: \n",
    "    * This is stateful (conversation's history is retained)\n",
    "    * It requires to import 3 classes\n",
    "        * Assistant: For example when we open ChatGPT, the prompt says \"How can I help you today?\"; it is an assistant\n",
    "            * Requires three parameters: name, instructions and which LLM to use\n",
    "        * Thread: series of input(prompts) and outputs(responses) realted to the Assistant\n",
    "        * Run: Processing of inputs & outputs and selecting the appropriate Assistant.\n",
    "            * Takes 2 arguments, Assistant (id) & Thread(id)\n",
    "            * Has 3 status: queued, in-process & completed (status of the task being performed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code_interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: Create Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "\n",
    "assistant : Assistant = client.beta.assistants.create(\n",
    "    name=\"Math tutor\",\n",
    "    instructions=\"Tou are a personal math tutor. Write and run code to answer math questions\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=[{\"type\":\"code_intrepreter\"}]     # can be a \"code_interpreter\" or a \"file_retriever\" or \"function_calling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2: Create a Thread\n",
    "* Takes no parameter\n",
    "* Inside of an Assistant there may be multiple threads \n",
    "* Inside of a thread, there are multiple messages (between the user & the assistant)\n",
    "    * We create messages, put these messages into threads and link these threads to the assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread : Thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3: Add a message to a Thread\n",
    "* Takes 3 parameters\n",
    "    * Thread ID\n",
    "    * Role of the user\n",
    "    * Content of the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "message : ThreadMessage = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,     # from previously created thread\n",
    "    role = \"user\",\n",
    "    content = \"Solve this problem: 3x + 11 = 14\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4: Run the Assistant\n",
    "* Takes 2 parameter\n",
    "    * Thread ID\n",
    "    * Assistant ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run : Run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id,\n",
    "    instructions = \"Please address the user as Jane Doe. The user has a premium account\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Run Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run : Run = client.beta.threads.runs.retrieve(\n",
    "    thread_id= thread.id,\n",
    "    run_id= run.id\n",
    ")\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5: Dispaly the Assistant's Response\n",
    "* To display the Assistant's response we need to retrieve the messages from the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve the run\n",
    "run = client.beta.threads.runs.retrieve(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to retrieve the messages from the run\n",
    "# messages : list[ThreadMessage] = client.beta.threads.messages.retrieve(\n",
    "#     thread_id = thread.id\n",
    "# )\n",
    "\n",
    "messages : list[ThreadMessage] = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display all the messages sent beteen the user & assistant\n",
    "\n",
    "for message in reversed(messages.data):  # reversed in order to get the oldest messages printrd out first and then the latest\n",
    "    print(message.role + \": \" + message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
